# ğŸš€ QWEN-DEV-CLI

**AI-Powered Code Assistant with MCP Integration**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![MCP](https://img.shields.io/badge/MCP-1.0-green.svg)](https://modelcontextprotocol.io/)
[![Gradio](https://img.shields.io/badge/Gradio-6.0-orange.svg)](https://gradio.app/)

> A hybrid CLI + Web code assistant that leverages Model Context Protocol (MCP) for context-aware code explanations and generation. Privacy-first, mobile-friendly, and lightning fast.

---

## âœ¨ Features

- ğŸš€ **Instant Responses** - HuggingFace Inference API for sub-2s latency
- ğŸ”’ **Privacy-First** - Optional local Ollama mode for complete data privacy
- ğŸ“± **Mobile Responsive** - Works seamlessly on any device (320px+)
- ğŸ”§ **MCP Integration** - Filesystem server for context-aware assistance
- âš¡ **Real-time Streaming** - Progressive token display for better UX
- ğŸ¯ **Dual Interface** - CLI for power users, Web UI for accessibility

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         QWEN-DEV-CLI                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  CLI (Typer)         Web UI (Gradio 6)      â”‚
â”‚  â”œâ”€ explain          â”œâ”€ Chat interface     â”‚
â”‚  â”œâ”€ generate         â”œâ”€ Streaming          â”‚
â”‚  â””â”€ serve            â””â”€ Mobile responsive  â”‚
â”‚                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Core Business Logic                 â”‚
â”‚  â”œâ”€ LLM Client (HF API + Ollama)           â”‚
â”‚  â”œâ”€ MCP Manager (Filesystem)               â”‚
â”‚  â””â”€ Context Builder                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         External Services                   â”‚
â”‚  â”œâ”€ HuggingFace Inference API              â”‚
â”‚  â”œâ”€ Ollama (Optional)                      â”‚
â”‚  â””â”€ MCP Filesystem Server                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/JuanCS-Dev/qwen-dev-cli.git
cd qwen-dev-cli

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Usage

#### CLI Mode

```bash
# Explain code
qwen-dev explain main.py

# Generate code
qwen-dev generate "Create a FastAPI endpoint for user authentication"

# Start web server
qwen-dev serve
```

#### Web UI Mode

```bash
# Start Gradio interface
python -m qwen_dev_cli

# Open browser at http://localhost:7860
```

---

## ğŸ› ï¸ Technology Stack

- **Frontend**: Gradio 6.0+ (Blocks API)
- **Backend**: Python 3.11+
- **LLM Primary**: HuggingFace Inference API
- **LLM Optional**: Ollama + Qwen 2.5 Coder 7B
- **MCP**: Model Context Protocol 1.0
- **CLI**: Typer + Rich

---

## ğŸ“¦ Project Structure

```
qwen-dev-cli/
â”œâ”€â”€ qwen_dev_cli/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ llm.py          # LLM client
â”‚   â”‚   â”œâ”€â”€ mcp.py          # MCP filesystem server
â”‚   â”‚   â”œâ”€â”€ context.py      # Context building
â”‚   â”‚   â””â”€â”€ config.py       # Configuration
â”‚   â”œâ”€â”€ cli.py              # Typer CLI interface
â”‚   â”œâ”€â”€ ui.py               # Gradio Blocks UI
â”‚   â””â”€â”€ utils.py            # Helpers
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ scripts/                # Utility scripts
â”œâ”€â”€ pyproject.toml          # Project metadata
â””â”€â”€ requirements.txt        # Dependencies
```

---

## ğŸ¯ MCP Integration

This project showcases Model Context Protocol integration through:

1. **Filesystem Server** - Direct file access for context injection
2. **Context Building** - Smart file selection and prompt construction
3. **Hybrid Approach** - CLI tools + Web interface working together

---

## ğŸš€ Deployment

### HuggingFace Spaces

This project is deployed on HuggingFace Spaces for instant access:

ğŸ”— **[Live Demo](https://huggingface.co/spaces/JuanCS-Dev/qwen-dev-cli)** *(coming soon)*

---

## ğŸ“Š Performance

- **TTFT**: < 2s (Time to First Token)
- **Throughput**: 12-18 tokens/sec
- **Cold Start**: ~5s (HF API) / ~45s (Ollama)
- **Mobile Support**: 320px+ width

---

## ğŸ¤ Contributing

This is a hackathon project for the **MCP 1st Birthday Hackathon** (Anthropic + Gradio).

Contributions welcome after the hackathon concludes!

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- **Anthropic** - For the amazing Claude and MCP
- **Gradio Team** - For the excellent UI framework
- **HuggingFace** - For Inference API and Spaces hosting
- **Ollama** - For local LLM capabilities

---

## ğŸ“ Contact

**Author**: Juan Carlos  
**GitHub**: [@JuanCS-Dev](https://github.com/JuanCS-Dev)  
**Project**: [qwen-dev-cli](https://github.com/JuanCS-Dev/qwen-dev-cli)

---

**Built for MCP 1st Birthday Hackathon ğŸ‰**

*Soli Deo Gloria* ğŸ™
